import { NextRequest, NextResponse } from 'next/server';
import { ProcessedFile, FileProcessingConfig, FileProcessingStatus } from '@/types';
import { extractTextFromFile, chunkText } from '@/lib/text-extraction';
import { generateEmbeddings } from '@/lib/rag-processing';
import { extractTopicsFromDocument } from '@/lib/document-analysis';
import fs from 'fs';
import path from 'path';

// Force Node.js runtime
export const runtime = 'nodejs';

// Configura√ß√£o padr√£o para o MVP
const DEFAULT_CONFIG: FileProcessingConfig = {
  chunkSize: 1000,
  chunkOverlap: 200,
  embeddingModel: 'text-embedding-3-small', // Mais barato para MVP
  batchSize: 10,
  strongMatchThreshold: 0.75,
  weakMatchThreshold: 0.60,
  enableOCR: false, // Desabilitado no MVP
  maxFileSize: 10 * 1024 * 1024, // 10MB
  supportedFormats: [
    'application/pdf',
    'text/plain',
    'text/markdown',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
  ]
};

// Armazenamento tempor√°rio para status de processamento
const processingStatuses = new Map<string, FileProcessingStatus>();

export async function GET(request: NextRequest) {
  const sessionId = request.nextUrl.searchParams.get('sessionId');

  if (!sessionId) {
    return NextResponse.json({ error: 'SessionId obrigat√≥rio' }, { status: 400 });
  }

  const status = processingStatuses.get(sessionId);

  if (!status) {
    return NextResponse.json({ error: 'Sess√£o n√£o encontrada' }, { status: 404 });
  }

  return NextResponse.json(status);
}

export async function POST(request: NextRequest) {
  const sessionId = `session-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;

  try {
    console.log('üöÄ Enhanced Upload API called');

    const formData = await request.formData();
    const files = formData.getAll('files') as File[];
    const configJson = formData.get('config') as string | null;

    if (!files || files.length === 0) {
      return NextResponse.json(
        { error: 'Nenhum arquivo foi enviado' },
        { status: 400 }
      );
    }

    // Parse configura√ß√£o ou usar padr√£o
    const config: FileProcessingConfig = configJson
      ? { ...DEFAULT_CONFIG, ...JSON.parse(configJson) }
      : DEFAULT_CONFIG;

    console.log(`üì§ Processing ${files.length} file(s) with enhanced pipeline`);

    // Inicializar status de processamento
    const status: FileProcessingStatus = {
      sessionId,
      currentStep: 'uploading',
      progress: 0,
      message: 'Iniciando processamento...',
      processedFiles: [],
      matches: [],
      errors: []
    };

    processingStatuses.set(sessionId, status);

    // Validar arquivos
    await updateStatus(sessionId, 'uploading', 10, 'Validando arquivos...');

    const validFiles: File[] = [];
    const errors: string[] = [];

    for (const file of files) {
      console.log(`üìã Validating file: ${file.name} (${file.type}, ${Math.round(file.size / 1024)}KB)`);

      if (file.size > config.maxFileSize) {
        errors.push(`Arquivo "${file.name}" muito grande`);
        continue;
      }

      const isSupported = config.supportedFormats.some(format =>
        file.type === format ||
        file.name.toLowerCase().endsWith(format.split('/').pop() || '')
      );

      if (!isSupported) {
        errors.push(`Arquivo "${file.name}" tem formato n√£o suportado`);
        continue;
      }

      validFiles.push(file);
    }

    if (validFiles.length === 0) {
      await updateStatus(sessionId, 'uploading', 0, 'Erro: Nenhum arquivo v√°lido', errors);
      return NextResponse.json(
        {
          error: 'Nenhum arquivo v√°lido encontrado',
          details: errors,
          sessionId
        },
        { status: 400 }
      );
    }

    console.log(`‚úÖ ${validFiles.length} arquivo(s) v√°lido(s)`);

    // Processar cada arquivo
    const processedFiles: ProcessedFile[] = [];

    for (let i = 0; i < validFiles.length; i++) {
      const file = validFiles[i];
      const fileProgress = Math.round((i / validFiles.length) * 80) + 20; // 20-100%

      try {
        await updateStatus(sessionId, 'extracting', fileProgress, `Extraindo texto de ${file.name}...`);

        // Extrair texto
        console.log(`üìÑ Extraindo texto de: ${file.name}`);
        const extractedText = await extractTextFromFile(file);

        // Chunking
        await updateStatus(sessionId, 'chunking', fileProgress + 5, `Dividindo texto em chunks...`);
        console.log(`‚úÇÔ∏è Fazendo chunking do texto`);
        const chunks = await chunkText(extractedText, config.chunkSize, config.chunkOverlap);

        // Embeddings
        await updateStatus(sessionId, 'embedding', fileProgress + 10, `Gerando embeddings...`);
        console.log(`üß† Gerando embeddings para ${chunks.length} chunks`);
        const embeddings = await generateEmbeddings(chunks, config.embeddingModel);

        // An√°lise de t√≥picos
        await updateStatus(sessionId, 'analyzing', fileProgress + 15, `Analisando t√≥picos...`);
        console.log(`üîç Extraindo t√≥picos do documento`);
        const { toc, topics } = await extractTopicsFromDocument(extractedText, file.name);

        const processedFile: ProcessedFile = {
          id: `file-${Date.now()}-${i}`,
          name: file.name,
          type: file.type,
          size: file.size,
          uploadedAt: new Date().toISOString(),
          rawText: extractedText,
          extractedMetadata: {
            pages: estimatePages(extractedText),
            headings: extractHeadings(extractedText),
            title: file.name.replace(/\.[^/.]+$/, ""),
            language: 'pt'
          },
          chunks: chunks.map((chunk: any, idx: number) => ({
            id: `chunk-${i}-${idx}`,
            fileId: `file-${Date.now()}-${i}`,
            text: chunk.text,
            order: idx,
            startChar: chunk.startChar,
            endChar: chunk.endChar,
            tokens: chunk.tokens,
            embedding: embeddings[idx]?.embedding,
            embeddingModel: config.embeddingModel
          })),
          extractedTOC: toc,
          extractedTopics: topics,
          processingStatus: 'complete'
        };

        processedFiles.push(processedFile);
        console.log(`‚úÖ Arquivo processado: ${file.name}`);

        // Salvar debug
        await saveProcessedFileDebug(processedFile);

      } catch (error) {
        console.error(`‚ùå Erro ao processar ${file.name}:`, error);
        status.errors.push({
          fileId: `file-${Date.now()}-${i}`,
          step: status.currentStep,
          error: error instanceof Error ? error.message : 'Erro desconhecido'
        });
      }
    }

    // Finalizar processamento
    await updateStatus(sessionId, 'complete', 100, `Processamento conclu√≠do! ${processedFiles.length} arquivo(s)`);

    console.log(`üéâ Enhanced upload conclu√≠do! ${processedFiles.length} arquivo(s) processado(s)`);

    return NextResponse.json({
      success: true,
      sessionId,
      processedFiles,
      config,
      message: `${processedFiles.length} arquivo(s) processado(s) com pipeline RAG`,
      stats: {
        totalFiles: processedFiles.length,
        totalChunks: processedFiles.reduce((sum, file) => sum + file.chunks.length, 0),
        totalTokens: processedFiles.reduce((sum, file) =>
          sum + file.chunks.reduce((chunkSum, chunk) => chunkSum + chunk.tokens, 0), 0)
      }
    });

  } catch (error) {
    console.error('‚ùå Error in enhanced upload:', error);

    await updateStatus(sessionId, 'uploading', 0, 'Erro interno no processamento');

    return NextResponse.json(
      {
        error: 'Erro no processamento enhanced',
        details: error instanceof Error ? error.message : 'Erro desconhecido',
        sessionId
      },
      { status: 500 }
    );
  }
}

// Utilit√°rios
async function updateStatus(
  sessionId: string,
  step: FileProcessingStatus['currentStep'],
  progress: number,
  message: string,
  errors: string[] = []
) {
  const status = processingStatuses.get(sessionId);
  if (status) {
    status.currentStep = step;
    status.progress = progress;
    status.message = message;
    if (errors.length > 0) {
      status.errors.push(...errors.map(error => ({
        fileId: 'unknown',
        step,
        error
      })));
    }
    processingStatuses.set(sessionId, status);
  }
}

function estimatePages(text: string): number {
  // Estimar p√°ginas baseado em caracteres (aproximadamente 2000 caracteres por p√°gina)
  return Math.ceil(text.length / 2000);
}

function extractHeadings(text: string): string[] {
  // Extrair headings simples (linhas que come√ßam com mai√∫scula e t√™m menos de 100 chars)
  const lines = text.split('\n');
  const headings: string[] = [];

  for (const line of lines) {
    const trimmed = line.trim();
    if (trimmed.length > 0 &&
        trimmed.length < 100 &&
        /^[A-Z]/.test(trimmed) &&
        !trimmed.includes('.') &&
        !/^\d/.test(trimmed)) {
      headings.push(trimmed);
    }
  }

  return headings.slice(0, 20); // M√°ximo 20 headings
}

async function saveProcessedFileDebug(file: ProcessedFile) {
  try {
    const debugDir = path.join(process.cwd(), 'debug', 'enhanced');
    if (!fs.existsSync(debugDir)) {
      fs.mkdirSync(debugDir, { recursive: true });
    }

    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const debugFilename = `${timestamp}_${file.name.replace(/[^a-zA-Z0-9.-]/g, '_')}_processed.json`;
    const debugPath = path.join(debugDir, debugFilename);

    const debugContent = {
      metadata: {
        fileName: file.name,
        processedAt: new Date().toISOString(),
        status: file.processingStatus
      },
      extractedMetadata: file.extractedMetadata,
      chunksCount: file.chunks.length,
      topicsCount: file.extractedTopics.length,
      tocEntries: file.extractedTOC.length,
      firstChunk: file.chunks[0]?.text.substring(0, 500),
      topics: file.extractedTopics.map(topic => ({
        title: topic.title,
        description: topic.description,
        chunksCount: topic.relatedChunks.length
      }))
    };

    fs.writeFileSync(debugPath, JSON.stringify(debugContent, null, 2), 'utf8');
    console.log(`üìù Debug processado salvo em ${debugPath}`);
  } catch (error) {
    console.error('Erro ao salvar debug processado:', error);
  }
}