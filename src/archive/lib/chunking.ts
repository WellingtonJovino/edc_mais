/**
 * Sistema de Chunking de Documentos para RAG
 * Processa documentos grandes em peda√ßos menores para melhor recupera√ß√£o
 */

export interface DocumentChunk {
  id: string;
  content: string;
  tokenCount: number;
  metadata: {
    source: string;
    chunkIndex: number;
    totalChunks: number;
    startPosition: number;
    endPosition: number;
    filename?: string;
    page?: number;
    section?: string;
    subsection?: string;
  };
  embedding?: number[];
  relevanceScore?: number;
}

export interface ChunkingConfig {
  maxTokens: number;          // 200-800 tokens por chunk
  overlapTokens: number;      // Sobreposi√ß√£o entre chunks (10-20% do maxTokens)
  preserveSentences: boolean; // Manter frases completas
  preserveParagraphs: boolean; // Manter par√°grafos completos quando poss√≠vel
  minChunkTokens: number;     // Tamanho m√≠nimo de chunk
}

const DEFAULT_CONFIG: ChunkingConfig = {
  maxTokens: 500,
  overlapTokens: 50,
  preserveSentences: true,
  preserveParagraphs: true,
  minChunkTokens: 100
};

/**
 * Estima n√∫mero de tokens em um texto (aproxima√ß√£o)
 */
function estimateTokenCount(text: string): number {
  // Aproxima√ß√£o: 4 caracteres por token em portugu√™s
  // Ajustado para ser mais conservador
  return Math.ceil(text.length / 3.5);
}

/**
 * Divide texto em senten√ßas preservando pontua√ß√£o
 */
function splitIntoSentences(text: string): string[] {
  // Regex para dividir em senten√ßas, considerando abrevia√ß√µes comuns
  const sentenceRegex = /(?<![A-Z][a-z])(?<![A-Z])(?<!Dr|Sr|Sra|Prof|Fig|Eq|etc|vs|p\.ex)\.(?=\s+[A-Z])|[!?]+(?=\s+[A-Z])/g;

  const sentences = text.split(sentenceRegex)
    .map(s => s.trim())
    .filter(s => s.length > 0);

  return sentences;
}

/**
 * Divide texto em par√°grafos
 */
function splitIntoParagraphs(text: string): string[] {
  return text.split(/\n\s*\n/)
    .map(p => p.trim())
    .filter(p => p.length > 0);
}

/**
 * Detecta estruturas hier√°rquicas (t√≠tulos, se√ß√µes)
 */
function detectStructure(text: string): Array<{type: 'title' | 'section' | 'subsection' | 'paragraph', content: string, level: number}> {
  const lines = text.split('\n').map(l => l.trim()).filter(l => l.length > 0);
  const structure: Array<{type: 'title' | 'section' | 'subsection' | 'paragraph', content: string, level: number}> = [];

  for (const line of lines) {
    // Detecta cabe√ßalhos markdown
    if (line.match(/^#{1,6}\s+/)) {
      const level = line.match(/^(#{1,6})/)?.[1].length || 1;
      const content = line.replace(/^#{1,6}\s+/, '');
      const type = level <= 2 ? 'section' : 'subsection';
      structure.push({ type, content, level });
    }
    // Detecta t√≠tulos em mai√∫sculo
    else if (line.length < 100 && line === line.toUpperCase() && line.match(/[A-Z\s]+/)) {
      structure.push({ type: 'title', content: line, level: 1 });
    }
    // Detecta se√ß√µes numeradas
    else if (line.match(/^\d+\.?\s+[A-Z]/)) {
      structure.push({ type: 'section', content: line, level: 2 });
    }
    // Detecta subse√ß√µes numeradas
    else if (line.match(/^\d+\.\d+\.?\s+/)) {
      structure.push({ type: 'subsection', content: line, level: 3 });
    }
    // Resto √© par√°grafo
    else {
      structure.push({ type: 'paragraph', content: line, level: 0 });
    }
  }

  return structure;
}

/**
 * Cria chunk com metadados apropriados
 */
function createChunk(
  content: string,
  chunkIndex: number,
  totalChunks: number,
  startPos: number,
  source: string,
  filename?: string,
  section?: string
): DocumentChunk {
  return {
    id: `chunk_${source}_${chunkIndex}_${Date.now()}`,
    content: content.trim(),
    tokenCount: estimateTokenCount(content),
    metadata: {
      source,
      chunkIndex,
      totalChunks,
      startPosition: startPos,
      endPosition: startPos + content.length,
      filename,
      section
    }
  };
}

/**
 * Chunking principal - divide documento em peda√ßos otimizados
 */
export function chunkDocument(
  text: string,
  source: string,
  config: Partial<ChunkingConfig> = {},
  filename?: string
): DocumentChunk[] {
  const fullConfig = { ...DEFAULT_CONFIG, ...config };
  const chunks: DocumentChunk[] = [];

  console.log(`üìÑ Processando documento: ${filename || source}`);
  console.log(`üìè Tamanho original: ${text.length} caracteres, ~${estimateTokenCount(text)} tokens`);

  // Se o documento √© pequeno, retorna como um chunk √∫nico
  if (estimateTokenCount(text) <= fullConfig.maxTokens) {
    console.log('üìù Documento pequeno, retornando como chunk √∫nico');
    return [createChunk(text, 0, 1, 0, source, filename)];
  }

  let processedText = text;
  let currentPosition = 0;
  let chunkIndex = 0;

  // Detecta estrutura se preservar par√°grafos est√° habilitado
  if (fullConfig.preserveParagraphs) {
    const paragraphs = splitIntoParagraphs(processedText);
    console.log(`üìä Detectados ${paragraphs.length} par√°grafos`);

    let currentChunk = '';
    let currentSection = '';

    for (let i = 0; i < paragraphs.length; i++) {
      const paragraph = paragraphs[i];
      const paragraphTokens = estimateTokenCount(paragraph);

      // Detecta se √© uma se√ß√£o/t√≠tulo
      if (paragraph.length < 100 && (paragraph === paragraph.toUpperCase() || paragraph.match(/^\d+\.?\s+[A-Z]/))) {
        currentSection = paragraph;

        // Se temos chunk acumulado, salva antes de iniciar nova se√ß√£o
        if (currentChunk.trim()) {
          const finalChunk = createChunk(currentChunk, chunkIndex, 0, currentPosition, source, filename, currentSection);
          chunks.push(finalChunk);
          currentPosition += currentChunk.length;
          chunkIndex++;
          currentChunk = '';
        }
      }

      // Se adicionar este par√°grafo ultrapassaria o limite
      if (estimateTokenCount(currentChunk + '\n\n' + paragraph) > fullConfig.maxTokens) {
        // Salva chunk atual se n√£o est√° vazio
        if (currentChunk.trim()) {
          const finalChunk = createChunk(currentChunk, chunkIndex, 0, currentPosition, source, filename, currentSection);
          chunks.push(finalChunk);
          currentPosition += currentChunk.length;
          chunkIndex++;
        }

        // Se o par√°grafo sozinho √© muito grande, divide em senten√ßas
        if (paragraphTokens > fullConfig.maxTokens) {
          const sentences = splitIntoSentences(paragraph);
          let sentenceChunk = '';

          for (const sentence of sentences) {
            if (estimateTokenCount(sentenceChunk + ' ' + sentence) > fullConfig.maxTokens) {
              if (sentenceChunk.trim()) {
                const finalChunk = createChunk(sentenceChunk, chunkIndex, 0, currentPosition, source, filename, currentSection);
                chunks.push(finalChunk);
                currentPosition += sentenceChunk.length;
                chunkIndex++;
              }
              sentenceChunk = sentence;
            } else {
              sentenceChunk += (sentenceChunk ? ' ' : '') + sentence;
            }
          }

          currentChunk = sentenceChunk;
        } else {
          currentChunk = paragraph;
        }
      } else {
        currentChunk += (currentChunk ? '\n\n' : '') + paragraph;
      }
    }

    // Adiciona √∫ltimo chunk se n√£o est√° vazio
    if (currentChunk.trim()) {
      const finalChunk = createChunk(currentChunk, chunkIndex, 0, currentPosition, source, filename, currentSection);
      chunks.push(finalChunk);
      chunkIndex++;
    }
  } else {
    // Chunking simples por caracteres com sobreposi√ß√£o
    const textLength = processedText.length;
    const maxChars = Math.floor(fullConfig.maxTokens * 3.5); // Aproxima√ß√£o de tokens para chars
    const overlapChars = Math.floor(fullConfig.overlapTokens * 3.5);

    while (currentPosition < textLength) {
      const endPosition = Math.min(currentPosition + maxChars, textLength);
      let chunkText = processedText.substring(currentPosition, endPosition);

      // Tenta quebrar em limite de palavra se preservar senten√ßas
      if (fullConfig.preserveSentences && endPosition < textLength) {
        const lastPeriod = chunkText.lastIndexOf('.');
        const lastSpace = chunkText.lastIndexOf(' ');

        if (lastPeriod > chunkText.length * 0.7) {
          chunkText = chunkText.substring(0, lastPeriod + 1);
        } else if (lastSpace > chunkText.length * 0.8) {
          chunkText = chunkText.substring(0, lastSpace);
        }
      }

      if (chunkText.trim() && estimateTokenCount(chunkText) >= fullConfig.minChunkTokens) {
        const finalChunk = createChunk(chunkText, chunkIndex, 0, currentPosition, source, filename);
        chunks.push(finalChunk);
        chunkIndex++;
      }

      currentPosition += chunkText.length - overlapChars;

      // Evita loop infinito
      if (chunkText.length === 0) {
        currentPosition = endPosition;
      }
    }
  }

  // Atualiza totalChunks em todos os chunks
  chunks.forEach(chunk => {
    chunk.metadata.totalChunks = chunks.length;
  });

  console.log(`‚úÖ Documento dividido em ${chunks.length} chunks`);
  console.log(`üìä Tamanhos dos chunks: ${chunks.map(c => c.tokenCount).join(', ')} tokens`);

  return chunks;
}

/**
 * Processa m√∫ltiplos documentos
 */
export function chunkMultipleDocuments(
  documents: Array<{content: string, filename: string, source: string}>,
  config: Partial<ChunkingConfig> = {}
): DocumentChunk[] {
  console.log(`üìö Processando ${documents.length} documentos`);

  const allChunks: DocumentChunk[] = [];

  for (const doc of documents) {
    const chunks = chunkDocument(doc.content, doc.source, config, doc.filename);
    allChunks.push(...chunks);
  }

  console.log(`‚úÖ Total de chunks gerados: ${allChunks.length}`);

  return allChunks;
}

/**
 * Filtra chunks por relev√¢ncia m√≠nima
 */
export function filterChunksByRelevance(
  chunks: DocumentChunk[],
  minRelevance: number = 0.3
): DocumentChunk[] {
  return chunks
    .filter(chunk => (chunk.relevanceScore || 0) >= minRelevance)
    .sort((a, b) => (b.relevanceScore || 0) - (a.relevanceScore || 0));
}

/**
 * Combina chunks relacionados se forem muito pequenos
 */
export function mergeSmallChunks(
  chunks: DocumentChunk[],
  minTokens: number = 100,
  maxTokens: number = 500
): DocumentChunk[] {
  const mergedChunks: DocumentChunk[] = [];
  let currentGroup: DocumentChunk[] = [];
  let currentTokens = 0;

  for (const chunk of chunks) {
    // Se adicionar este chunk ultrapassaria o limite, processa grupo atual
    if (currentTokens + chunk.tokenCount > maxTokens && currentGroup.length > 0) {
      // Combina chunks do grupo atual
      if (currentGroup.length === 1) {
        mergedChunks.push(currentGroup[0]);
      } else {
        const combinedContent = currentGroup.map(c => c.content).join('\n\n');
        const combinedChunk = createChunk(
          combinedContent,
          mergedChunks.length,
          0,
          currentGroup[0].metadata.startPosition,
          currentGroup[0].metadata.source,
          currentGroup[0].metadata.filename,
          currentGroup[0].metadata.section
        );
        mergedChunks.push(combinedChunk);
      }

      currentGroup = [];
      currentTokens = 0;
    }

    currentGroup.push(chunk);
    currentTokens += chunk.tokenCount;
  }

  // Processa √∫ltimo grupo
  if (currentGroup.length > 0) {
    if (currentGroup.length === 1) {
      mergedChunks.push(currentGroup[0]);
    } else {
      const combinedContent = currentGroup.map(c => c.content).join('\n\n');
      const combinedChunk = createChunk(
        combinedContent,
        mergedChunks.length,
        0,
        currentGroup[0].metadata.startPosition,
        currentGroup[0].metadata.source,
        currentGroup[0].metadata.filename,
        currentGroup[0].metadata.section
      );
      mergedChunks.push(combinedChunk);
    }
  }

  return mergedChunks;
}

/**
 * Extrai resumo de cada chunk para contexto
 */
export function extractChunkSummaries(chunks: DocumentChunk[]): Array<DocumentChunk & {summary: string}> {
  return chunks.map(chunk => {
    // Pega primeiras 2 senten√ßas como resumo
    const sentences = splitIntoSentences(chunk.content);
    const summary = sentences.slice(0, 2).join(' ').substring(0, 150);

    return {
      ...chunk,
      summary: summary + (summary.length < chunk.content.length ? '...' : '')
    };
  });
}